
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>9. Using Slurm Indirectly &#8212; Read the Docs Template 1.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/classic.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">Read the Docs Template 1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">9. </span>Using Slurm Indirectly</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="using-slurm-indirectly">
<h1><span class="section-number">9. </span>Using Slurm Indirectly<a class="headerlink" href="#using-slurm-indirectly" title="Permalink to this headline">¶</a></h1>
<section id="id1">
<h2><span class="section-number">9.1. </span>Using Slurm indirectly<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Instead of controlling job preparation and submission directly via the command line it is possible to access slurm through packages in (programming) environments. A number of options are presented.</p>
<section id="slurm-in-r">
<h3><span class="section-number">9.1.1. </span>Slurm in R<a class="headerlink" href="#slurm-in-r" title="Permalink to this headline">¶</a></h3>
<p>Using the rslurm package an R session running on the headnode (omics-h0) that can run jobs on the cluster. The functions <code class="docutils literal notranslate"><span class="pre">slurm_call</span></code> and <code class="docutils literal notranslate"><span class="pre">slurm_apply</span></code> can be used to submit computationally expensive jobs on the compute nodes. The help provided in the package about  the functions gives an example. To test demonstrate it on Crunchomics with some slight modifications</p>
<div class="highlight-R notranslate"><div class="highlight"><pre><span></span><span class="nf">require</span><span class="p">(</span><span class="s">&quot;rslurm&quot;</span><span class="p">)</span>
<span class="c1"># Create a data frame of mean/sd values for normal distributions</span>
<span class="n">pars</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">par_m</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="n">length.out</span> <span class="o">=</span> <span class="m">1000</span><span class="p">),</span>
           <span class="n">par_sd</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="n">length.out</span> <span class="o">=</span> <span class="m">1000</span><span class="p">))</span>
<span class="c1">#</span>
<span class="c1"># Create a function to parallelize</span>
<span class="n">ftest</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">par_m</span><span class="p">,</span> <span class="n">par_sd</span><span class="p">)</span> <span class="p">{</span>
<span class="n">samp</span> <span class="o">&lt;-</span> <span class="nf">rnorm</span><span class="p">(</span><span class="m">2e6</span><span class="p">,</span> <span class="n">par_m</span><span class="p">,</span> <span class="n">par_sd</span><span class="p">)</span>
<span class="nf">c</span><span class="p">(</span><span class="n">s_m</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">samp</span><span class="p">),</span> <span class="n">s_sd</span> <span class="o">=</span> <span class="nf">sd</span><span class="p">(</span><span class="n">samp</span><span class="p">))</span>
<span class="p">}</span>
<span class="c1">#</span>
<span class="n">sjob1</span> <span class="o">&lt;-</span> <span class="nf">slurm_apply</span><span class="p">(</span><span class="n">ftest</span><span class="p">,</span> <span class="n">pars</span><span class="p">,</span><span class="n">slurm_options</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">mem</span><span class="o">=</span><span class="s">&quot;1G&quot;</span><span class="p">))</span>
<span class="nf">get_job_status</span><span class="p">(</span><span class="n">sjob1</span><span class="p">)</span>
<span class="c1"># wait until get_job_status(sjob1)$completed</span>
<span class="c1"># the job will take about a minute if resources are available.</span>
<span class="n">res</span> <span class="o">&lt;-</span> <span class="nf">get_slurm_out</span><span class="p">(</span><span class="n">sjob1</span><span class="p">,</span> <span class="s">&quot;table&quot;</span><span class="p">)</span>
<span class="nf">all.equal</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span> <span class="c1"># Confirm correct output</span>
<span class="nf">cleanup_files</span><span class="p">(</span><span class="n">sjob1</span><span class="p">)</span>
</pre></div>
</div>
<p>Some notes while running it on Crunchomics:</p>
<ul class="simple">
<li><p>While running jobs the package creates a map in the current directory which is used to communicate data to the R processes on the nodes called <em>slurm_[jobname]</em>. The working directory changes to that directory so relative file paths in the function will not work.</p></li>
<li><p>The cleanup_files function can be used to remove this directory.</p></li>
<li><p>By default the jobs will have 100MB of memory. Rather than giving up, the typical behaviour of R is to become very very slow if it does not have enough memory. Use <code class="docutils literal notranslate"><span class="pre">slurm_options=list(mem=&quot;1G&quot;)</span></code> in the slurm_call/slurm_apply to get enough(Change 1G to the needed amount) memory for your function.</p></li>
<li><p>R has to run on the Slurm-cluster (Jobs can not be submitted from omics-app01)</p></li>
</ul>
</section>
<section id="slurm-in-python">
<h3><span class="section-number">9.1.2. </span>Slurm in Python<a class="headerlink" href="#slurm-in-python" title="Permalink to this headline">¶</a></h3>
<p>A package called simple_slurm is available in the madpy3 environment. Check <a class="reference external" href="https://pypi.org/project/simple-slurm/">Simple Slurm pypi.org</a> for package documentation and examples.</p>
</section>
<section id="slurm-and-snakemake">
<h3><span class="section-number">9.1.3. </span>Slurm and Snakemake<a class="headerlink" href="#slurm-and-snakemake" title="Permalink to this headline">¶</a></h3>
<p>Existing snakemake pipelines can be run on the cluster (almost) without change, using a parameter file (cluster.json) snakemake is told how jobs have to be submitted. Below is an example setup of a normal  snakefile which maps a number of samples to a genome. This demonstration can be copied and  run using the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cp -r /zfs/omics/software/doc/Crunchomics_intro/SnakeDemo .
<span class="nb">cd</span> SnakeDemo
ls
<span class="c1"># 3 files and an empty directory are copied</span>
<span class="c1">#</span>
<span class="c1"># Snakemake has to be available use</span>
<span class="c1"># source /zfs/omics/software/v_envs/madpy3/bin/activate</span>
<span class="c1"># if which snakemake comes back without result</span>
<span class="c1">#</span>
batch snakemake.cmd
</pre></div>
</div>
<p>Check the snakefile using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat Snakefile
</pre></div>
</div>
<p>Snakefile is a typical snakemake input file to trim and map some samples, but the process should work for any Snakefile.  The snakefile can be processed unchanged by snakemake utilizing the cluster using the a parameter file:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#cluster.json</span>
<span class="p">{</span><span class="w"></span>
<span class="s">&quot;__default__&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;time&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;00:30:00&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;n&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;c&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;memory&quot;</span><span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;2G&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;partition&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;all&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;output&quot;</span><span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;logs/slurm-%A_{rule}.{wildcards}.out&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;error&quot;</span><span class="w">     </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;logs/slurm-%A_{rule}.{wildcards}.err&quot;</span><span class="p">,</span><span class="w"></span>
<span class="p">},</span><span class="w"></span>
<span class="s">&quot;align_to_database&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;time&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;02:00:00&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;memory&quot;</span><span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;10G&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;c&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="p">},</span><span class="w"></span>
<span class="s">&quot;trim_read&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;time&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;01:00:00&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;c&quot;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>In the parameter file the options values can be specified for how snakemake has to configure the slurm jobs. In it the number of cores, the amount of memory etc. is given for the rules. If the name of the rule  is not given snakemake uses the values given in <code class="docutils literal notranslate"><span class="pre">__default__</span></code></p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">--cluster</span></code> and <code class="docutils literal notranslate"><span class="pre">--cluster-config</span></code> parameters snakemake is able replace the job execution commands with slurm batch jobs.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>snakemake -j <span class="m">8</span> --cluster-config cluster.json --cluster <span class="s2">&quot;sbatch  -p {cluster.partition} -n {cluster.n}  -c {cluster.c} -t {cluster.time} --mem {cluster.memory} -o {cluster.output} &quot;</span>
</pre></div>
</div>
<p>The command above can be wrapped into an sbatch script (the file: snakemake.cmd)  In this way the snakemake program itself runs as a slurm job. Note that sbatch commands executed from within an sbatch job will run in a new and separate allocation independent of the allocation from which sbatch is run. While the snakemake program itself runs on a single core the batches it runs like the mapping tasks can use 8 cores.</p>
<p>The mapping of parameters defined in the cluster.json file to the sbatch command. Snakemake takes care that jobs are submitted using the parameters in the cluster.json file. By default the parameters in <code class="docutils literal notranslate"><span class="pre">__default__</span></code> are used. For rules that match a clause in the cluster.json file for example <code class="docutils literal notranslate"><span class="pre">align_to_database</span></code> changes from the default can be included for example the the number of cores (8 instead of 1) and the time (2 hour intead of 30 minutes).
As mentioned in the introduction snakefiles can be run <strong>almost</strong> unchanged. Some rules do very little actual work and it make little sense to setup and schedule a job for it for example creating a directory. These rules can be declared as <code class="docutils literal notranslate"><span class="pre">localrules</span></code> at the top of the snakefile. This means snakemake will execute them directly instead of submitting them as a slurm job. Also depending on if and how thread counts are dealt with in the snakefile tweaking can improve the utilization of the allocated resources.</p>
<p>The snakemake parameter <code class="docutils literal notranslate"><span class="pre">-j</span></code> which normally limits the number of cores used by snakemake limits the number of concurrently submitted jobs regardless of the number of cores each job allocates. Setting -j to high values such as 999  as is done in some examples on the internet is usually not a good idea as it might claim the complete cluster.</p>
<p>Using snakemake in combination with the (super fast NVMe SSD) local scratch partition for temporary storage adds an extra challenge. The main mode of operation of snakemake is checking the existence of files. However, a snakemake process running on the headnode can not access the scratch on the nodes. A possibility is to configure snakemake (in cluster.json) to run on a single node and to combine that with running snakemake itself using sbatch in the selected node.</p>
</section>
</section>
</section>
<section id="debugging-slurm-jobs">
<h1><span class="section-number">10. </span>Debugging Slurm jobs<a class="headerlink" href="#debugging-slurm-jobs" title="Permalink to this headline">¶</a></h1>
<p>If things do not run as expected there are a number of tools and tricks to find out why.</p>
<ul class="simple">
<li><p>Initially <code class="docutils literal notranslate"><span class="pre">squeue</span></code> can be used to get the state of the job. Is it in the queue, running or ended. A job which request resources which are not available is queued until the resources become available. If a jobs ask for 6 nodes it will be queued but never run as there are only 5 compute nodes.</p></li>
<li><p>Check the output file of the batchjob (slurm_[jobid].out or the name given using –output parameter).  Use <code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">slurm_[jobid].out</span></code> or <code class="docutils literal notranslate"><span class="pre">tail</span> <span class="pre">slurm_[jobid].out</span></code> to check what the job sent to its standard output.</p></li>
<li><p>To see if the job runs as expected, an additional interactive job can be started on the node the job is running on using <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-w</span> <span class="pre">[nodeX]</span> <span class="pre">--pty</span> <span class="pre">bash</span> <span class="pre">-i</span></code>.  The commands <code class="docutils literal notranslate"><span class="pre">top</span></code> and <code class="docutils literal notranslate"><span class="pre">htop</span></code> are useful to see which programs are running and if the program is  using the allocated resources as expected.</p></li>
<li><p>If it is not possible to allocate a job on the node an option is to directly ssh into node. This is only possible if you have an active job on the particular node.</p></li>
<li><p>A common problem is lack of memory. Memory is also limited in by the slurm allocation. The default memory allocation is 100MB. While this is fine for some, it is not enough for many jobs. Some jobs simply give up with an error if they don’t have enough memory. Others try to make the best of it. This might result in jobs, which are expected to complete in a couple of hours to run for days. A telltale sign of this happening is that memory usage shown by top is close to or equal to the allocation asked for. While setting up jobs keep in mind the compute nodes have 512GB each. That is  8G for each of the 64 cores on average. Don’t allocate what you do not need: this might be used by others. It is not unreasonable to allocate 128GB of memory for a 16-core job.</p></li>
</ul>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">9. Using Slurm Indirectly</a><ul>
<li><a class="reference internal" href="#id1">9.1. Using Slurm indirectly</a><ul>
<li><a class="reference internal" href="#slurm-in-r">9.1.1. Slurm in R</a></li>
<li><a class="reference internal" href="#slurm-in-python">9.1.2. Slurm in Python</a></li>
<li><a class="reference internal" href="#slurm-and-snakemake">9.1.3. Slurm and Snakemake</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#debugging-slurm-jobs">10. Debugging Slurm jobs</a></li>
</ul>

  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/source/slurm_indirect.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">Read the Docs Template 1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">9. </span>Using Slurm Indirectly</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2014, Read the Docs.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    </div>
  </body>
</html>